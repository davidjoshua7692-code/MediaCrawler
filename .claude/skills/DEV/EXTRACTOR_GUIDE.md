# é€šç”¨æ•°æ®æå–å·¥å…·ä½¿ç”¨æŒ‡å—

## ğŸ“– ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [é¢„è®¾æ¨¡æ¿](#é¢„è®¾æ¨¡æ¿)
- [APIå‚è€ƒ](#apiå‚è€ƒ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
cd d:\MediaCrawler-main\.claude\skills\analyzing-social-media-data
pip install pandas
```

### åŸºç¡€ç”¨æ³•

```bash
# æå–åŒ…å«å…³é”®è¯çš„å¸–å­
python extractor.py contents.csv --keywords "å’–å•¡å…"

# æå–ä»·æ ¼ä¿¡æ¯
python extractor.py contents.csv --extract-prices

# æå–çƒ­é—¨å¸–å­
python extractor.py contents.csv --top-posts --top 10
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. å…³é”®è¯æœç´¢ (`--keywords`)

æ ¹æ®ä¸€ä¸ªæˆ–å¤šä¸ªå…³é”®è¯æå–ç›¸å…³å¸–å­ã€‚

**ç¤ºä¾‹ï¼š**
```bash
# æœç´¢å•ä¸ªå…³é”®è¯
python extractor.py contents.csv --keywords "ä¸€å°ºèŠ±å›­"

# æœç´¢å¤šä¸ªå…³é”®è¯
python extractor.py contents.csv --keywords "å’–å•¡" "è‡ªä¹ " "åŠå…¬"

# æŒ‡å®šæœç´¢å­—æ®µ
python extractor.py contents.csv --keywords "å®å±±" --fields title desc

# ä¿å­˜ç»“æœ
python extractor.py contents.csv --keywords "è‡ªä¹ " --save results.json
```

**å‚æ•°è¯´æ˜ï¼š**
- `--keywords`: å…³é”®è¯åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰
- `--fields`: æœç´¢çš„å­—æ®µï¼ˆé»˜è®¤: title descï¼‰
- `--top`: è¿”å›å‰Næ¡ç»“æœï¼ˆé»˜è®¤: 20ï¼‰
- `--sort-by`: æ’åºå­—æ®µï¼ˆé»˜è®¤: liked_countï¼‰

---

### 2. æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… (`--pattern`)

ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç‰¹å®šæ¨¡å¼çš„æ•°æ®ã€‚

**ç¤ºä¾‹ï¼š**
```bash
# æå–ä»·æ ¼ï¼ˆXXå…ƒ/å¤©ï¼‰
python extractor.py contents.csv --pattern "(\d+)å…ƒ.*å¤©"

# æå–ç”µè¯å·ç 
python extractor.py contents.csv --pattern "1[3-9]\d{9}"

# æå–é‚®ç®±
python extractor.py contents.csv --pattern "[\w\.-]+@[\w\.-]+\.\w+"

# æå–æ—¥æœŸ
python extractor.py contents.csv --pattern "\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}"
```

---

### 3. ä»·æ ¼æå– (`--extract-prices`)

è‡ªåŠ¨è¯†åˆ«å¹¶æå–ä»·æ ¼ç›¸å…³ä¿¡æ¯ã€‚

**ç¤ºä¾‹ï¼š**
```bash
# æå–æ‰€æœ‰ä»·æ ¼ä¿¡æ¯
python extractor.py contents.csv --extract-prices

# è¿”å›å‰50æ¡
python extractor.py contents.csv --extract-prices --top 50

# ä¿å­˜ä¸ºCSV
python extractor.py contents.csv --extract-prices --save prices.csv
```

**è‡ªåŠ¨è¯†åˆ«çš„ä»·æ ¼æ ¼å¼ï¼š**
- `30å…ƒ/å¤©` â†’ æå–ä¸º "30 å…ƒ/å¤©"
- `å…è´¹` â†’ æå–ä¸º "å…è´¹"
- `30æ¬¡å¡` â†’ æå–ä¸º "30 æ¬¡å¡"
- `200æœˆå¡` â†’ æå–ä¸º "200 æœˆå¡"

---

### 4. åœ°ç†ä½ç½®æå– (`--extract-locations`)

æå–æ–‡æœ¬ä¸­æåˆ°çš„åœ°ç†ä½ç½®ã€‚

**ç¤ºä¾‹ï¼š**
```bash
# æå–åœ°ç†ä½ç½®
python extractor.py contents.csv --extract-locations

# è¿”å›TOP 15
python extractor.py contents.csv --extract-locations --top 15

# ä¿å­˜ç»“æœ
python extractor.py contents.csv --extract-locations --save locations.json
```

---

### 5. çƒ­é—¨å¸–å­æå– (`--top-posts`)

æå–ç‚¹èµæ•°æœ€é«˜çš„å¸–å­ã€‚

**ç¤ºä¾‹ï¼š**
```bash
# æå–TOP 20çƒ­é—¨å¸–å­
python extractor.py contents.csv --top-posts

# è¿‡æ»¤ç‚¹èµæ•°>100çš„å¸–å­
python extractor.py contents.csv --top-posts --min-likes 100

# æå–TOP 50
python extractor.py contents.csv --top-posts --top 50
```

---

### 6. ç»Ÿè®¡ä¿¡æ¯ (`--statistics`)

æ˜¾ç¤ºæ•°æ®é›†çš„æ•´ä½“ç»Ÿè®¡ä¿¡æ¯ã€‚

**ç¤ºä¾‹ï¼š**
```bash
python extractor.py contents.csv --statistics
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
ğŸ“ˆ æ•°æ®ç»Ÿè®¡ä¿¡æ¯
================================================================================
total_posts: 120
total_likes: 38772
avg_likes: 323.1
max_likes: 3481
total_comments: 4260
avg_comments: 35.5
```

---

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæå–ç‰¹å®šå“ç‰Œçš„å¸–å­

```bash
# æå–æ‰€æœ‰æåˆ°"ä¸€å°ºèŠ±å›­"çš„å¸–å­
python extractor.py contents.csv --keywords "ä¸€å°ºèŠ±å›­" --top 30
```

### ç¤ºä¾‹2ï¼šæŸ¥æ‰¾30å…ƒä»¥å†…çš„åº—é“º

```bash
# æå–ä»·æ ¼ä¿¡æ¯å¹¶ç­›é€‰
python extractor.py contents.csv --extract-prices --top 50
```

### ç¤ºä¾‹3ï¼šåˆ†ææŸåŒºåŸŸçš„çƒ­é—¨åœ°ç‚¹

```bash
# æå–å®å±±åŒºçš„åœ°ç†ä½ç½®åˆ†å¸ƒ
python extractor.py contents.csv --keywords "å®å±±" --extract-locations --top 20
```

### ç¤ºä¾‹4ï¼šæ‰¾åˆ°é«˜äº’åŠ¨çš„åŠå…¬åœºæ‰€å¸–å­

```bash
# æå–"åŠå…¬"ç›¸å…³çš„é«˜èµå¸–å­
python extractor.py contents.csv --keywords "åŠå…¬" "å·¥ä½œ" --top 20 --sort-by liked_count
```

### ç¤ºä¾‹5ï¼šç»„åˆå¤šä¸ªå…³é”®è¯

```bash
# æœç´¢åŒæ—¶åŒ…å«"å®‰é™"å’Œ"å’–å•¡å…"çš„å¸–å­
python extractor.py contents.csv --keywords "å®‰é™" "å’–å•¡å…" --fields title desc
```

---

## ğŸ¨ é¢„è®¾æ¨¡æ¿

### æ¨¡æ¿1ï¼šå’–å•¡å…åˆ†æ

```bash
# 1. æå–æ‰€æœ‰å’–å•¡å…å“ç‰Œ
python extractor.py contents.csv --keywords "æ˜Ÿå·´å…‹" "ä¸€å°ºèŠ±å›­" "Manner" "ç‘å¹¸" --top 50 --save cafes.json

# 2. æå–ä»·æ ¼ä¿¡æ¯
python extractor.py contents.csv --extract-prices --top 30 --save prices.json

# 3. æå–åœ°ç†ä½ç½®
python extractor.py contents.csv --extract-locations --top 15 --save locations.json

# 4. æå–çƒ­é—¨å¸–å­
python extractor.py contents.csv --keywords "å’–å•¡" --top 20 --save top_posts.json
```

### æ¨¡æ¿2ï¼šè‡ªä¹ å®¤åˆ†æ

```bash
# 1. æå–è‡ªä¹ å®¤ç›¸å…³å¸–å­
python extractor.py contents.csv --keywords "è‡ªä¹ " "å­¦ä¹ " "å›¾ä¹¦é¦†" --top 30

# 2. æå–ä»·æ ¼ä¿¡æ¯
python extractor.py contents.csv --extract-prices --top 50

# 3. æå–24å°æ—¶è¥ä¸šçš„åœºæ‰€
python extractor.py contents.csv --pattern "24å°æ—¶" --top 20
```

### æ¨¡æ¿3ï¼šæ—…æ¸¸æ™¯ç‚¹åˆ†æ

```bash
# 1. æå–æ™¯ç‚¹ç›¸å…³å¸–å­
python extractor.py contents.csv --keywords "æ™¯ç‚¹" "æ—…æ¸¸" "æ‰“å¡" --top 50

# 2. æå–åœ°ç†ä½ç½®
python extractor.py contents.csv --extract-locations --top 30

# 3. æå–çƒ­é—¨å¸–å­
python extractor.py contents.csv --top-posts --min-likes 500 --top 30
```

---

## ğŸ”§ APIå‚è€ƒ

### Python API ä½¿ç”¨

```python
from extractor import UniversalExtractor

# åˆå§‹åŒ–
extractor = UniversalExtractor(
    contents_file='data.csv',
    comments_file='comments.csv'  # å¯é€‰
)

# 1. å…³é”®è¯æœç´¢
results = extractor.extract_by_keywords(
    keywords=['å’–å•¡', 'è‡ªä¹ '],
    search_fields=['title', 'desc'],
    top_n=20,
    sort_by='liked_count'
)

# 2. æ­£åˆ™åŒ¹é…
results = extractor.extract_by_pattern(
    pattern=r'(\d+)å…ƒ.*å¤©',
    search_fields=['title', 'desc'],
    top_n=20
)

# 3. æå–ä»·æ ¼
results = extractor.extract_prices(top_n=20)

# 4. æå–åœ°ç†ä½ç½®
locations = extractor.extract_locations(top_n=10)

# 5. æå–çƒ­é—¨å¸–å­
top_posts = extractor.extract_top_posts(top_n=20, min_likes=100)

# 6. è·å–ç»Ÿè®¡ä¿¡æ¯
stats = extractor.extract_statistics()

# 7. è‡ªå®šä¹‰æå–
def my_filter(row):
    return 'å’–å•¡' in str(row.get('title', ''))

def my_extractor(row):
    return {
        'title': row.get('title', ''),
        'liked': row.get('liked_count', 0),
        'custom_field': 'è‡ªå®šä¹‰å€¼'
    }

results = extractor.extract_custom(
    filter_func=my_filter,
    extract_func=my_extractor,
    top_n=20
)

# 8. æ‰“å°ç»“æœ
extractor.print_results(results, title="æˆ‘çš„æå–ç»“æœ")

# 9. ä¿å­˜ç»“æœ
extractor.save_results(results, 'output.json', format='json')
extractor.save_results(results, 'output.csv', format='csv')
```

---

## ğŸ’¡ é«˜çº§æŠ€å·§

### 1. é“¾å¼æ“ä½œ

```bash
# å…ˆæå–å…³é”®è¯ï¼Œå†ä»ç»“æœä¸­æå–ä»·æ ¼
python extractor.py contents.csv --keywords "è‡ªä¹ " --save temp.json
python extractor.py temp.json --extract-prices
```

### 2. ç»„åˆå¤šä¸ªè¿‡æ»¤æ¡ä»¶

```python
# Pythonè„šæœ¬ä¸­ç»„åˆæ¡ä»¶
extractor = UniversalExtractor('contents.csv')

# å…ˆæå–å…³é”®è¯
results1 = extractor.extract_by_keywords(['å’–å•¡', 'å®‰é™'])

# å†ä»ç»“æœä¸­è¿‡æ»¤
filtered = [r for r in results1 if r['liked'] > 100]

# ä¿å­˜
extractor.save_results(filtered, 'filtered_results.json')
```

### 3. è‡ªå®šä¹‰ä»·æ ¼æ¨¡å¼

```python
# æ·»åŠ è‡ªå®šä¹‰ä»·æ ¼æ¨¡å¼
custom_patterns = [
    (r'(\d+)ç¾å…ƒ', 'ç¾å…ƒ'),
    (r'(\d+)æ¸¯å¸', 'æ¸¯å¸'),
    (r'æŠ˜æ‰£.*?(\d+)æŠ˜', r'\1æŠ˜'),
]

results = extractor.extract_prices(
    price_patterns=custom_patterns,
    top_n=50
)
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æå–å¤šä¸ªCSVæ–‡ä»¶çš„æ•°æ®ï¼Ÿ

```bash
# æ–¹æ³•1ï¼šåˆå¹¶CSVåå†æå–
# Windows
type file1.csv file2.csv > combined.csv

# Linux/Mac
cat file1.csv file2.csv > combined.csv

# ç„¶åæå–
python extractor.py combined.csv --keywords "å’–å•¡"
```

### Q2: å¦‚ä½•å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜ï¼Ÿ

```python
# ä½¿ç”¨encodingå‚æ•°
df = pd.read_csv('file.csv', encoding='utf-8-sig')
extractor = UniversalExtractor(df)
```

### Q3: å¦‚ä½•æé«˜åŒ¹é…ç²¾åº¦ï¼Ÿ

```bash
# ä½¿ç”¨æ›´ç²¾ç¡®çš„å…³é”®è¯
python extractor.py contents.csv --keywords "å®å±±åŒºå’–å•¡å…"  # æ›´ç²¾ç¡®

# æˆ–ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
python extractor.py contents.csv --pattern "å®å±±.*?å’–å•¡å…"
```

### Q4: ç»“æœå¤ªå¤šæ€ä¹ˆåŠï¼Ÿ

```bash
# é™åˆ¶è¿”å›æ•°é‡
python extractor.py contents.csv --keywords "å’–å•¡" --top 10

# æˆ–è®¾ç½®æœ€å°ç‚¹èµæ•°
python extractor.py contents.csv --top-posts --min-likes 500 --top 20
```

### Q5: å¦‚ä½•æ‰¹é‡å¤„ç†å¤šä¸ªå…³é”®è¯ï¼Ÿ

```bash
# åˆ›å»ºæ‰¹å¤„ç†è„šæœ¬
for keyword in "æ˜Ÿå·´å…‹" "ä¸€å°ºèŠ±å›­" "Manner" "ç‘å¹¸"
do
    python extractor.py contents.csv --keywords "$keyword" --save "${keyword}.json"
done
```

---

## ğŸ“ è¾“å‡ºæ ¼å¼è¯´æ˜

### JSONæ ¼å¼

```json
[
  {
    "title": "å¸–å­æ ‡é¢˜",
    "desc": "å¸–å­æè¿°...",
    "liked": 1234,
    "collected": 567,
    "comment_count": 89,
    "note_id": "abc123",
    "matched_keyword": "å’–å•¡"
  }
]
```

### CSVæ ¼å¼

| title | desc | liked | collected | comment_count | note_id |
|-------|------|-------|-----------|---------------|---------|
| å¸–å­æ ‡é¢˜ | æè¿°... | 1234 | 567 | 89 | abc123 |

---

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.0.0 (2026-01-20)
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… æ”¯æŒå…³é”®è¯æœç´¢
- âœ… æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
- âœ… æ”¯æŒä»·æ ¼æå–
- âœ… æ”¯æŒåœ°ç†ä½ç½®æå–
- âœ… æ”¯æŒçƒ­é—¨å¸–å­æå–
- âœ… æ”¯æŒç»Ÿè®¡ä¿¡æ¯
- âœ… æ”¯æŒè‡ªå®šä¹‰æå–å‡½æ•°
- âœ… æ”¯æŒJSON/CSVå¯¼å‡º

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

---

## ğŸ“„ è®¸å¯è¯

MIT License
