"""
FinBERT ä¸­æ–‡é‡‘èæƒ…æ„Ÿåˆ†ææ¨¡å—
ä¸“é—¨é’ˆå¯¹è‚¡å¸‚è®¨è®ºè¿›è¡Œæƒ…ç»ªåˆ†æ
"""
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# å°è¯•å¯¼å…¥ transformers
try:
    from transformers import (
        TextClassificationPipeline,
        AutoModelForSequenceClassification,
        BertTokenizerFast
    )
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False


class FinBertAnalyzer:
    """FinBERT ä¸­æ–‡é‡‘èæƒ…æ„Ÿåˆ†æå™¨"""

    def __init__(self, model_path: str = "./models/finbert_chinese/"):
        """
        åˆå§‹åŒ– FinBERT æ¨¡å‹

        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°æˆ– Hugging Faceï¼‰
        """
        self.model_path = model_path
        self.model_loaded = False
        self.pipeline = None

        if not TRANSFORMERS_AVAILABLE:
            print("âš ï¸  transformers åº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ FinBERT")
            print("   å®‰è£…æ–¹æ³•: uv add torch transformers")
            return

        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path_obj = Path(model_path)
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
            print("   è¯·å…ˆè¿è¡Œ: python download_finbert_model.py")
            return

        try:
            # åŠ è½½æ¨¡å‹
            print(f"ğŸ“¦ æ­£åœ¨åŠ è½½ FinBERT æ¨¡å‹: {model_path}")

            model = AutoModelForSequenceClassification.from_pretrained(
                model_path,
                output_attentions=True
            )

            tokenizer = BertTokenizerFast.from_pretrained(model_path)

            # åˆ›å»º pipeline
            self.pipeline = TextClassificationPipeline(
                model=model,
                tokenizer=tokenizer,
                top_k=None,  # è¿”å›æ‰€æœ‰åˆ†æ•°
                device=0  # GPU (RTX 4070 Ti SUPER)
            )

            self.model_loaded = True
            print("âœ… FinBERT æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print("   æ ‡ç­¾æ˜ å°„: LABEL_0=ä¸­æ€§, LABEL_1=æ­£é¢(çœ‹æ¶¨), LABEL_2=è´Ÿé¢(çœ‹è·Œ)")

        except Exception as e:
            print(f"âŒ FinBERT æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("   å°†å›é€€åˆ°å…³é”®è¯åŒ¹é…æ–¹æ³•")

    def analyze(self, text: str) -> Dict[str, any]:
        """
        åˆ†æå•æ¡æ–‡æœ¬çš„é‡‘èæƒ…æ„Ÿ

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            {
                'sentiment': 'bullish' | 'bearish' | 'neutral',
                'confidence': float,
                'scores': {æ ‡ç­¾: åˆ†æ•°},
                'method': 'finbert' | 'keyword'
            }
        """
        if not text or pd.isna(text):
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'scores': {},
                'method': 'keyword'
            }

        text = str(text)

        # å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…
        if not self.model_loaded:
            return self._keyword_analyze(text)

        try:
            # ä½¿ç”¨ FinBERT åˆ†æ
            results = self.pipeline(text[:512])  # é™åˆ¶512 tokens

            # results æ ¼å¼: [[{label: 'LABEL_0', score: 0.1}, ...]]
            scores = results[0]

            # æ‰¾å‡ºæœ€é«˜åˆ†çš„æ ‡ç­¾
            top_result = max(scores, key=lambda x: x['score'])
            label = top_result['label']
            confidence = top_result['score']

            # æ˜ å°„åˆ°è‚¡å¸‚æƒ…ç»ªï¼ˆæ”¯æŒä¸¤ç§æ ‡ç­¾æ ¼å¼ï¼‰
            label_mapping_label = {
                'LABEL_0': 'neutral',   # ä¸­æ€§
                'LABEL_1': 'bullish',   # æ­£é¢ â†’ çœ‹æ¶¨
                'LABEL_2': 'bearish'    # è´Ÿé¢ â†’ çœ‹è·Œ
            }

            label_mapping_text = {
                'Neutral': 'neutral',
                'Positive': 'bullish',
                'Negative': 'bearish'
            }

            sentiment = label_mapping_label.get(label) or label_mapping_text.get(label, 'neutral')

            # æ„å»ºåˆ†æ•°å­—å…¸
            scores_dict = {
                'neutral': next((s['score'] for s in scores if s['label'] in ['LABEL_0', 'Neutral']), 0.0),
                'bullish': next((s['score'] for s in scores if s['label'] in ['LABEL_1', 'Positive']), 0.0),
                'bearish': next((s['score'] for s in scores if s['label'] in ['LABEL_2', 'Negative']), 0.0),
            }

            # ç»†åŒ–æƒ…ç»ªåˆ†ç±»ï¼ˆ9ç±»ï¼‰
            fine_grained_sentiment = self._get_fine_grained_sentiment(scores_dict)

            return {
                'sentiment': sentiment,
                'fine_grained': fine_grained_sentiment,  # æ–°å¢ï¼šç»†ç²’åº¦æƒ…ç»ª
                'confidence': confidence,
                'scores': scores_dict,
                'method': 'finbert'
            }

        except Exception as e:
            print(f"âš ï¸  FinBERT åˆ†æå‡ºé”™: {e}ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…")
            return self._keyword_analyze(text)

    def _get_fine_grained_sentiment(self, scores: Dict[str, float]) -> str:
        """
        æ ¹æ®åˆ†æ•°åˆ†å¸ƒè·å–ç»†ç²’åº¦æƒ…ç»ªï¼ˆ9ç±»ï¼‰

        Args:
            scores: {'bullish': 0.99, 'bearish': 0.005, 'neutral': 0.005}

        Returns:
            ç»†ç²’åº¦æƒ…ç»ªæ ‡ç­¾
        """
        bullish = scores.get('bullish', 0.0)
        bearish = scores.get('bearish', 0.0)
        neutral = scores.get('neutral', 0.0)

        # å¼ºçƒˆçœ‹æ¶¨ï¼šPositive > 80% ä¸” Positive > Negative*2
        if bullish > 0.8 and bullish > bearish * 2:
            return 'å¼ºçƒˆçœ‹æ¶¨ğŸ“ˆğŸ“ˆ'

        # çœ‹æ¶¨ï¼šPositive > 60% ä¸” Positive > Negative*1.5
        if bullish > 0.6 and bullish > bearish * 1.5:
            return 'çœ‹æ¶¨ğŸ“ˆ'

        # åæ¶¨ï¼š50% < Positive â‰¤ 60%
        if 0.5 < bullish <= 0.6:
            return 'åæ¶¨ğŸ“Š'

        # å¼ºçƒˆçœ‹è·Œï¼šNegative > 80% ä¸” Negative > Positive*2
        if bearish > 0.8 and bearish > bullish * 2:
            return 'å¼ºçƒˆçœ‹è·ŒğŸ“‰ğŸ“‰'

        # çœ‹è·Œï¼šNegative > 60% ä¸” Negative > Positive*1.5
        if bearish > 0.6 and bearish > bullish * 1.5:
            return 'çœ‹è·ŒğŸ“‰'

        # åè·Œï¼š50% < Negative â‰¤ 60%
        if 0.5 < bearish <= 0.6:
            return 'åè·ŒğŸ“Š'

        # ä¸­æ€§åŒºé—´
        if neutral > 0.4:
            if bearish > bullish * 1.2:
                return 'ä¸­æ€§åç©ºâšªğŸ“‰'
            elif bullish > bearish * 1.2:
                return 'ä¸­æ€§åå¤šâšªğŸ“ˆ'
            else:
                return 'çº¯ä¸­æ€§âšª'

        # ä½ç½®ä¿¡åº¦ï¼ˆæ‰€æœ‰åˆ†æ•°éƒ½è¾ƒä½ï¼‰
        if max(bullish, bearish, neutral) < 0.5:
            return 'ä¸ç¡®å®šâ“'

        return 'ä¸­æ€§âšª'

    def _keyword_analyze(self, text: str) -> Dict[str, any]:
        """
        å…³é”®è¯åŒ¹é…åˆ†æï¼ˆå›é€€æ–¹æ¡ˆï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # çœ‹æ¶¨å…³é”®è¯
        bullish_keywords = [
            'æ¶¨', 'åŠ ä»“', 'ä¹°å…¥', 'çœ‹å¤š', 'èµ·é£', 'çªç ´', 'ç‰›å¸‚',
            'æŒæœ‰', 'ä¸å–', 'ç»§ç»­æ¶¨', 'è¿˜èƒ½æ¶¨', 'ç›®æ ‡', 'å¥½', 'ç‰›',
            'å¼º', 'ç¨³', 'å€¼', 'ä½å¸', 'è¡¥ä»“', 'æœºä¼š', 'ä¹°'
        ]

        # çœ‹è·Œå…³é”®è¯
        bearish_keywords = [
            'è·Œ', 'å‡ä»“', 'å–å‡º', 'çœ‹ç©º', 'å›è°ƒ', 'ç†Šå¸‚',
            'å‡ºè´§', 'é«˜ä¼°', 'è´µ', 'å¼±', 'é£é™©', 'æ€•', 'è·Œäº†',
            'æ¸…ä»“', 'å‰²è‚‰', 'äºæŸ', 'å¥—', 'æ€•è·Œ', 'è¿˜ä¼šè·Œ'
        ]

        text_lower = text.lower()
        bullish_score = sum(1 for kw in bullish_keywords if kw in text_lower)
        bearish_score = sum(1 for kw in bearish_keywords if kw in text_lower)

        if bullish_score > bearish_score:
            sentiment = 'bullish'
            confidence = min(0.6 + bullish_score * 0.1, 0.95)
        elif bearish_score > bullish_score:
            sentiment = 'bearish'
            confidence = min(0.6 + bearish_score * 0.1, 0.95)
        else:
            sentiment = 'neutral'
            confidence = 0.5

        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'scores': {
                'bullish': 0.7 if sentiment == 'bullish' else 0.2,
                'bearish': 0.7 if sentiment == 'bearish' else 0.2,
                'neutral': 0.6 if sentiment == 'neutral' else 0.2,
            },
            'method': 'keyword'
        }

    def batch_analyze(
        self,
        texts: List[str],
        show_progress: bool = True
    ) -> List[Dict[str, any]]:
        """
        æ‰¹é‡åˆ†ææ–‡æœ¬

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(texts)

        for i, text in enumerate(texts, 1):
            if show_progress and i % 10 == 0:
                print(f"  è¿›åº¦: {i}/{total} ({i/total*100:.1f}%)")

            result = self.analyze(text)
            results.append(result)

        return results


# ============================================================================
# æ··åˆåˆ†æå™¨ï¼ˆå…³é”®è¯ + FinBERTï¼‰
# ============================================================================

class HybridSentimentAnalyzer:
    """
    æ··åˆæƒ…ç»ªåˆ†æå™¨
    ä¼˜å…ˆä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰ï¼Œä¸ç¡®å®šæ—¶ä½¿ç”¨ FinBERTï¼ˆç²¾å‡†ï¼‰
    """

    def __init__(self, model_path: str = "./models/finbert_chinese/"):
        """
        åˆå§‹åŒ–æ··åˆåˆ†æå™¨

        Args:
            model_path: FinBERT æ¨¡å‹è·¯å¾„
        """
        self.finbert = FinBertAnalyzer(model_path)

        # å…³é”®è¯
        self.bullish_keywords = [
            'æ¶¨', 'åŠ ä»“', 'ä¹°å…¥', 'çœ‹å¤š', 'èµ·é£', 'çªç ´', 'ç‰›å¸‚',
            'æŒæœ‰', 'ä¸å–', 'ç»§ç»­æ¶¨', 'è¿˜èƒ½æ¶¨', 'ç›®æ ‡', 'å¥½', 'ç‰›',
            'å¼º', 'ç¨³', 'å€¼', 'ä½å¸', 'è¡¥ä»“', 'æœºä¼š', 'ä¹°'
        ]

        self.bearish_keywords = [
            'è·Œ', 'å‡ä»“', 'å–å‡º', 'çœ‹ç©º', 'å›è°ƒ', 'ç†Šå¸‚',
            'å‡ºè´§', 'é«˜ä¼°', 'è´µ', 'å¼±', 'é£é™©', 'æ€•', 'è·Œäº†',
            'æ¸…ä»“', 'å‰²è‚‰', 'äºæŸ', 'å¥—', 'æ€•è·Œ', 'è¿˜ä¼šè·Œ'
        ]

    def analyze(self, text: str) -> Dict[str, any]:
        """
        æ··åˆåˆ†æ

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not text or pd.isna(text):
            return {'sentiment': 'neutral', 'confidence': 0.0, 'method': 'keyword'}

        text = str(text)

        # 1. å…ˆç”¨å…³é”®è¯å¿«é€ŸåŒ¹é…
        text_lower = text.lower()
        bullish_score = sum(1 for kw in self.bullish_keywords if kw in text_lower)
        bearish_score = sum(1 for kw in self.bearish_keywords if kw in text_lower)

        # 2. åˆ¤æ–­å…³é”®è¯æ˜¯å¦ç¡®å®š
        if abs(bullish_score - bearish_score) >= 2:
            # å…³é”®è¯å¾—åˆ†å·®å¼‚æ˜æ˜¾ï¼Œç›´æ¥è¿”å›
            if bullish_score > bearish_score:
                sentiment = 'bullish'
                confidence = min(0.6 + bullish_score * 0.1, 0.95)
            else:
                sentiment = 'bearish'
                confidence = min(0.6 + bearish_score * 0.1, 0.95)

            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'scores': {
                    'bullish': 0.8 if sentiment == 'bullish' else 0.2,
                    'bearish': 0.8 if sentiment == 'bearish' else 0.2,
                    'neutral': 0.3,
                },
                'method': 'keyword'
            }

        # 3. å…³é”®è¯ä¸ç¡®å®šï¼Œä½¿ç”¨ FinBERT
        if self.finbert.model_loaded:
            return self.finbert.analyze(text)
        else:
            # FinBERT æœªåŠ è½½ï¼Œä½¿ç”¨å…³é”®è¯ç»“æœ
            if bullish_score > bearish_score:
                return {'sentiment': 'bullish', 'confidence': 0.55, 'method': 'keyword'}
            elif bearish_score > bullish_score:
                return {'sentiment': 'bearish', 'confidence': 0.55, 'method': 'keyword'}
            else:
                return {'sentiment': 'neutral', 'confidence': 0.5, 'method': 'keyword'}
