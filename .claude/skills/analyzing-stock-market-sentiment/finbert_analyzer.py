"""
FinBERT ä¸­æ–‡é‡‘èžæƒ…æ„Ÿåˆ†æžæ¨¡å—
ä¸“é—¨é’ˆå¯¹è‚¡å¸‚è®¨è®ºè¿›è¡Œæƒ…ç»ªåˆ†æž
"""
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# å°è¯•å¯¼å…¥ transformers
try:
    from transformers import (
        TextClassificationPipeline,
        AutoModelForSequenceClassification,
        BertTokenizerFast
    )
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False


class FinBertAnalyzer:
    """FinBERT ä¸­æ–‡é‡‘èžæƒ…æ„Ÿåˆ†æžå™¨"""

    def __init__(self, model_path: str = "./models/finbert_chinese/"):
        """
        åˆå§‹åŒ– FinBERT æ¨¡åž‹

        Args:
            model_path: æ¨¡åž‹è·¯å¾„ï¼ˆæœ¬åœ°æˆ– Hugging Faceï¼‰
        """
        self.model_path = model_path
        self.model_loaded = False
        self.pipeline = None

        if not TRANSFORMERS_AVAILABLE:
            print("âš ï¸  transformers åº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ FinBERT")
            print("   å®‰è£…æ–¹æ³•: uv add torch transformers")
            return

        # æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path_obj = Path(model_path)
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
            print("   è¯·å…ˆè¿è¡Œ: python download_finbert_model.py")
            return

        try:
            # åŠ è½½æ¨¡åž‹
            print(f"ðŸ“¦ æ­£åœ¨åŠ è½½ FinBERT æ¨¡åž‹: {model_path}")

            model = AutoModelForSequenceClassification.from_pretrained(
                model_path,
                output_attentions=True
            )

            tokenizer = BertTokenizerFast.from_pretrained(model_path)

            # åˆ›å»º pipeline
            self.pipeline = TextClassificationPipeline(
                model=model,
                tokenizer=tokenizer,
                top_k=None,  # è¿”å›žæ‰€æœ‰åˆ†æ•°
                device=-1  # CPUï¼Œå¦‚æžœæœ‰GPUæ”¹æˆ0
            )

            self.model_loaded = True
            print("âœ… FinBERT æ¨¡åž‹åŠ è½½æˆåŠŸ!")
            print("   æ ‡ç­¾æ˜ å°„: LABEL_0=ä¸­æ€§, LABEL_1=æ­£é¢(çœ‹æ¶¨), LABEL_2=è´Ÿé¢(çœ‹è·Œ)")

        except Exception as e:
            print(f"âŒ FinBERT æ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
            print("   å°†å›žé€€åˆ°å…³é”®è¯åŒ¹é…æ–¹æ³•")

    def analyze(self, text: str) -> Dict[str, any]:
        """
        åˆ†æžå•æ¡æ–‡æœ¬çš„é‡‘èžæƒ…æ„Ÿ

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            {
                'sentiment': 'bullish' | 'bearish' | 'neutral',
                'confidence': float,
                'scores': {æ ‡ç­¾: åˆ†æ•°},
                'method': 'finbert' | 'keyword'
            }
        """
        if not text or pd.isna(text):
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'scores': {},
                'method': 'keyword'
            }

        text = str(text)

        # å¦‚æžœæ¨¡åž‹æœªåŠ è½½ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…
        if not self.model_loaded:
            return self._keyword_analyze(text)

        try:
            # ä½¿ç”¨ FinBERT åˆ†æž
            results = self.pipeline(text[:512])  # é™åˆ¶512 tokens

            # results æ ¼å¼: [[{label: 'LABEL_0', score: 0.1}, ...]]
            scores = results[0]

            # æ‰¾å‡ºæœ€é«˜åˆ†çš„æ ‡ç­¾
            top_result = max(scores, key=lambda x: x['score'])
            label = top_result['label']
            confidence = top_result['score']

            # æ˜ å°„åˆ°è‚¡å¸‚æƒ…ç»ªï¼ˆæ”¯æŒä¸¤ç§æ ‡ç­¾æ ¼å¼ï¼‰
            label_mapping_label = {
                'LABEL_0': 'neutral',   # ä¸­æ€§
                'LABEL_1': 'bullish',   # æ­£é¢ â†’ çœ‹æ¶¨
                'LABEL_2': 'bearish'    # è´Ÿé¢ â†’ çœ‹è·Œ
            }

            label_mapping_text = {
                'Neutral': 'neutral',
                'Positive': 'bullish',
                'Negative': 'bearish'
            }

            sentiment = label_mapping_label.get(label) or label_mapping_text.get(label, 'neutral')

            # æž„å»ºåˆ†æ•°å­—å…¸
            scores_dict = {
                'neutral': next((s['score'] for s in scores if s['label'] in ['LABEL_0', 'Neutral']), 0.0),
                'bullish': next((s['score'] for s in scores if s['label'] in ['LABEL_1', 'Positive']), 0.0),
                'bearish': next((s['score'] for s in scores if s['label'] in ['LABEL_2', 'Negative']), 0.0),
            }

            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'scores': scores_dict,
                'method': 'finbert'
            }

        except Exception as e:
            print(f"âš ï¸  FinBERT åˆ†æžå‡ºé”™: {e}ï¼Œå›žé€€åˆ°å…³é”®è¯åŒ¹é…")
            return self._keyword_analyze(text)

    def _keyword_analyze(self, text: str) -> Dict[str, any]:
        """
        å…³é”®è¯åŒ¹é…åˆ†æžï¼ˆå›žé€€æ–¹æ¡ˆï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            åˆ†æžç»“æžœå­—å…¸
        """
        # çœ‹æ¶¨å…³é”®è¯
        bullish_keywords = [
            'æ¶¨', 'åŠ ä»“', 'ä¹°å…¥', 'çœ‹å¤š', 'èµ·é£ž', 'çªç ´', 'ç‰›å¸‚',
            'æŒæœ‰', 'ä¸å–', 'ç»§ç»­æ¶¨', 'è¿˜èƒ½æ¶¨', 'ç›®æ ‡', 'å¥½', 'ç‰›',
            'å¼º', 'ç¨³', 'å€¼', 'ä½Žå¸', 'è¡¥ä»“', 'æœºä¼š', 'ä¹°'
        ]

        # çœ‹è·Œå…³é”®è¯
        bearish_keywords = [
            'è·Œ', 'å‡ä»“', 'å–å‡º', 'çœ‹ç©º', 'å›žè°ƒ', 'ç†Šå¸‚',
            'å‡ºè´§', 'é«˜ä¼°', 'è´µ', 'å¼±', 'é£Žé™©', 'æ€•', 'è·Œäº†',
            'æ¸…ä»“', 'å‰²è‚‰', 'äºæŸ', 'å¥—', 'æ€•è·Œ', 'è¿˜ä¼šè·Œ'
        ]

        text_lower = text.lower()
        bullish_score = sum(1 for kw in bullish_keywords if kw in text_lower)
        bearish_score = sum(1 for kw in bearish_keywords if kw in text_lower)

        if bullish_score > bearish_score:
            sentiment = 'bullish'
            confidence = min(0.6 + bullish_score * 0.1, 0.95)
        elif bearish_score > bullish_score:
            sentiment = 'bearish'
            confidence = min(0.6 + bearish_score * 0.1, 0.95)
        else:
            sentiment = 'neutral'
            confidence = 0.5

        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'scores': {
                'bullish': 0.7 if sentiment == 'bullish' else 0.2,
                'bearish': 0.7 if sentiment == 'bearish' else 0.2,
                'neutral': 0.6 if sentiment == 'neutral' else 0.2,
            },
            'method': 'keyword'
        }

    def batch_analyze(
        self,
        texts: List[str],
        show_progress: bool = True
    ) -> List[Dict[str, any]]:
        """
        æ‰¹é‡åˆ†æžæ–‡æœ¬

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            åˆ†æžç»“æžœåˆ—è¡¨
        """
        results = []
        total = len(texts)

        for i, text in enumerate(texts, 1):
            if show_progress and i % 10 == 0:
                print(f"  è¿›åº¦: {i}/{total} ({i/total*100:.1f}%)")

            result = self.analyze(text)
            results.append(result)

        return results


# ============================================================================
# æ··åˆåˆ†æžå™¨ï¼ˆå…³é”®è¯ + FinBERTï¼‰
# ============================================================================

class HybridSentimentAnalyzer:
    """
    æ··åˆæƒ…ç»ªåˆ†æžå™¨
    ä¼˜å…ˆä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰ï¼Œä¸ç¡®å®šæ—¶ä½¿ç”¨ FinBERTï¼ˆç²¾å‡†ï¼‰
    """

    def __init__(self, model_path: str = "./models/finbert_chinese/"):
        """
        åˆå§‹åŒ–æ··åˆåˆ†æžå™¨

        Args:
            model_path: FinBERT æ¨¡åž‹è·¯å¾„
        """
        self.finbert = FinBertAnalyzer(model_path)

        # å…³é”®è¯
        self.bullish_keywords = [
            'æ¶¨', 'åŠ ä»“', 'ä¹°å…¥', 'çœ‹å¤š', 'èµ·é£ž', 'çªç ´', 'ç‰›å¸‚',
            'æŒæœ‰', 'ä¸å–', 'ç»§ç»­æ¶¨', 'è¿˜èƒ½æ¶¨', 'ç›®æ ‡', 'å¥½', 'ç‰›',
            'å¼º', 'ç¨³', 'å€¼', 'ä½Žå¸', 'è¡¥ä»“', 'æœºä¼š', 'ä¹°'
        ]

        self.bearish_keywords = [
            'è·Œ', 'å‡ä»“', 'å–å‡º', 'çœ‹ç©º', 'å›žè°ƒ', 'ç†Šå¸‚',
            'å‡ºè´§', 'é«˜ä¼°', 'è´µ', 'å¼±', 'é£Žé™©', 'æ€•', 'è·Œäº†',
            'æ¸…ä»“', 'å‰²è‚‰', 'äºæŸ', 'å¥—', 'æ€•è·Œ', 'è¿˜ä¼šè·Œ'
        ]

    def analyze(self, text: str) -> Dict[str, any]:
        """
        æ··åˆåˆ†æž

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            åˆ†æžç»“æžœå­—å…¸
        """
        if not text or pd.isna(text):
            return {'sentiment': 'neutral', 'confidence': 0.0, 'method': 'keyword'}

        text = str(text)

        # 1. å…ˆç”¨å…³é”®è¯å¿«é€ŸåŒ¹é…
        text_lower = text.lower()
        bullish_score = sum(1 for kw in self.bullish_keywords if kw in text_lower)
        bearish_score = sum(1 for kw in self.bearish_keywords if kw in text_lower)

        # 2. åˆ¤æ–­å…³é”®è¯æ˜¯å¦ç¡®å®š
        if abs(bullish_score - bearish_score) >= 2:
            # å…³é”®è¯å¾—åˆ†å·®å¼‚æ˜Žæ˜¾ï¼Œç›´æŽ¥è¿”å›ž
            if bullish_score > bearish_score:
                sentiment = 'bullish'
                confidence = min(0.6 + bullish_score * 0.1, 0.95)
            else:
                sentiment = 'bearish'
                confidence = min(0.6 + bearish_score * 0.1, 0.95)

            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'scores': {
                    'bullish': 0.8 if sentiment == 'bullish' else 0.2,
                    'bearish': 0.8 if sentiment == 'bearish' else 0.2,
                    'neutral': 0.3,
                },
                'method': 'keyword'
            }

        # 3. å…³é”®è¯ä¸ç¡®å®šï¼Œä½¿ç”¨ FinBERT
        if self.finbert.model_loaded:
            return self.finbert.analyze(text)
        else:
            # FinBERT æœªåŠ è½½ï¼Œä½¿ç”¨å…³é”®è¯ç»“æžœ
            if bullish_score > bearish_score:
                return {'sentiment': 'bullish', 'confidence': 0.55, 'method': 'keyword'}
            elif bearish_score > bullish_score:
                return {'sentiment': 'bearish', 'confidence': 0.55, 'method': 'keyword'}
            else:
                return {'sentiment': 'neutral', 'confidence': 0.5, 'method': 'keyword'}
