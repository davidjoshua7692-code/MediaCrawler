



"""

DEPRECATEDï¼šä¸éœ€è¦è„šæœ¬è‡ªåŠ¨åŒ–æ‰§è¡Œã€‚çˆ¬è™«è‡ªåŠ¨æ¥åˆ°æ•°æ®åˆ†æ

MediaCrawler è‡ªåŠ¨åˆ†ææ¡¥æ¥å·¥å…·
æ ¹æ®çˆ¬è™«é…ç½®è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„åˆ†æç­–ç•¥
"""
import os
import re
from pathlib import Path
from datetime import datetime
import pandas as pd

def get_latest_files(platform, data_type='csv'):
    """
    è·å–æŒ‡å®šå¹³å°çš„æœ€æ–°æ•°æ®æ–‡ä»¶

    Args:
        platform: å¹³å°æ ‡è¯†ç¬¦ (xhs, dy, biliç­‰)
        data_type: æ•°æ®ç±»å‹ (csv, json, excelç­‰)

    Returns:
        tuple: (contents_file, comments_file) æ–‡ä»¶è·¯å¾„
    """
    base_path = Path(f'data/{platform}/{data_type}')

    if not base_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {base_path}")
        return None, None

    # æŸ¥æ‰¾å†…å®¹æ–‡ä»¶
    contents_files = list(base_path.glob('search_contents_*.csv'))
    contents_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

    # æŸ¥æ‰¾è¯„è®ºæ–‡ä»¶
    comments_files = list(base_path.glob('search_comments_*.csv'))
    comments_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

    contents_file = contents_files[0] if contents_files else None
    comments_file = comments_files[0] if comments_files else None

    return contents_file, comments_file

def analyze_from_config(config_file='config/base_config.py'):
    """
    è¯»å–çˆ¬è™«é…ç½®å¹¶è‡ªåŠ¨è¿è¡Œåˆ†æ

    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        dict: åˆ†æç»“æœ
    """
    # è¯»å–é…ç½®
    config_globals = {
        '__name__': '__main__',
        '__builtins__': __builtins__
    }

    with open(config_file, 'r', encoding='utf-8') as f:
        config_content = f.read()

    # ç®€å•æå–å…³é”®é…ç½®ï¼ˆé¿å…æ‰§è¡Œæ•´ä¸ªé…ç½®æ–‡ä»¶ï¼‰
    import re

    def extract_config_var(content, var_name, default=''):
        pattern = rf'{var_name}\s*=\s*[\'"]([^\'\"]*)[\'"]'
        match = re.search(pattern, content)
        return match.group(1) if match else default

    platform = extract_config_var(config_content, 'PLATFORM', 'xhs')
    keywords = extract_config_var(config_content, 'KEYWORDS', '')
    crawler_type = extract_config_var(config_content, 'CRAWLER_TYPE', 'search')
    save_option = extract_config_var(config_content, 'SAVE_DATA_OPTION', 'csv')

    print(f"ğŸ“‹ ä»é…ç½®è¯»å–å‚æ•°:")
    print(f"  å¹³å°: {platform}")
    print(f"  å…³é”®è¯: {keywords}")
    print(f"  çˆ¬å–ç±»å‹: {crawler_type}")
    print(f"  ä¿å­˜æ ¼å¼: {save_option}")

    # æ£€æµ‹æ•°æ®ç±»å‹
    if save_option not in ['csv', 'json', 'excel']:
        print(f"âš ï¸ å½“å‰ä»…æ”¯æŒ CSV/JSON/Excel æ ¼å¼åˆ†æ")
        return None

    # è·å–æœ€æ–°æ–‡ä»¶
    contents_file, comments_file = get_latest_files(platform, save_option)

    if not contents_file:
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«: uv run python main.py")
        return None

    print(f"\nğŸ“‚ æ£€æµ‹åˆ°æ•°æ®æ–‡ä»¶:")
    print(f"  å†…å®¹æ–‡ä»¶: {contents_file}")
    if comments_file:
        print(f"  è¯„è®ºæ–‡ä»¶: {comments_file}")
    else:
        print(f"  è¯„è®ºæ–‡ä»¶: æœªæ‰¾åˆ°ï¼ˆå¯é€‰ï¼‰")

    # è‡ªåŠ¨é€‰æ‹©åˆ†æå…³é”®è¯
    custom_keywords = auto_select_keywords(keywords)

    if custom_keywords:
        print(f"\nğŸ¯ è‡ªåŠ¨é€‰æ‹©å…³é”®è¯é…ç½®: {custom_keywords.get('category', 'é€šç”¨')}")

    # å¯¼å…¥åˆ†æå™¨
    import sys
    project_root = Path(__file__).parent.parent
    sys.path.insert(0, str(project_root))

    from claude.skills.mediacrawler_analyzer.analyze import analyze_mediacrawler_data

    # è¿è¡Œåˆ†æ
    results = analyze_mediacrawler_data(
        contents_file=str(contents_file),
        comments_file=str(comments_file) if comments_file else None,
        custom_keywords=custom_keywords,
        custom_title=f"ğŸ“Š {keywords} - æ•°æ®åˆ†ææŠ¥å‘Š"
    )

    return results

def auto_select_keywords(keywords):
    """
    æ ¹æ®æœç´¢å…³é”®è¯è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„åˆ†æé…ç½®

    Args:
        keywords: æœç´¢å…³é”®è¯å­—ç¬¦ä¸²

    Returns:
        dict: è‡ªå®šä¹‰å…³é”®è¯é…ç½®
    """
    keywords_lower = keywords.lower()

    # å’–å•¡å…/åŠå…¬åœºæ™¯
    if any(word in keywords_lower for word in ['å’–å•¡', 'cafe', 'åŠå…¬', 'è‡ªä¹ ', 'å·¥ä½œ', 'ç¬”è®°æœ¬', 'ä¹…å']):
        return {
            'category': 'å’–å•¡å…/åŠå…¬ç©ºé—´',
            'features': {
                'å®‰é™': ['å®‰é™', 'æ¸…å‡€', 'ä¸åµ', 'silent', 'quiet'],
                'æ’åº§': ['æ’åº§', 'ç”µæº', 'å……ç”µ', 'plug'],
                'ç½‘ç»œ': ['wifi', 'wi-fi', 'ç½‘é€Ÿ', 'ç½‘ç»œ'],
                'åœè½¦ä½': ['åœè½¦', 'parking', 'åœè½¦åˆ¸'],
                'æœ‰å•æ‰€': ['å•æ‰€', 'å«ç”Ÿé—´', 'æ´—æ‰‹é—´', 'wc'],
                'è¥ä¸šæ—¶é—´': ['è¥ä¸š', 'å¼€é—¨', 'å…³é—¨', '24å°æ—¶'],
                'ä»·æ ¼': ['ä»·æ ¼', 'ä¾¿å®œ', 'è´µ', 'å®æƒ ', 'äººå‡'],
            },
            'sentiment': {
                'positive': ['æ¨è', 'å¥½', 'ä¸é”™', 'èˆ’æœ', 'æ£’', 'å–œæ¬¢', 'é€‚åˆ', 'æ–¹ä¾¿'],
                'negative': ['åµ', 'è´µ', 'å·®', 'ä¸å¥½', 'å¤±æœ›', 'æ…¢', 'æŒ¤']
            }
        }

    # ç¾é£Ÿåœºæ™¯
    elif any(word in keywords_lower for word in ['ç¾é£Ÿ', 'å¥½åƒ', 'é¤å…', 'å°åƒ', 'èœ', 'åƒ']):
        return {
            'category': 'ç¾é£Ÿæ¨è',
            'features': {
                'å£å‘³': ['å¥½åƒ', 'ç¾å‘³', 'æ­£å®—', 'å£æ„Ÿ', 'å‘³é“', 'é¦™'],
                'ç¯å¢ƒ': ['è£…ä¿®', 'æ°›å›´', 'ç¯å¢ƒ', 'è£…æ½¢', 'æ¡£æ¬¡', 'å¹²å‡€'],
                'æœåŠ¡': ['æœåŠ¡', 'æœåŠ¡å‘˜', 'æ€åº¦', 'çƒ­æƒ…', 'å‘¨åˆ°'],
                'ä»·æ ¼': ['ä¾¿å®œ', 'å®æƒ ', 'æ€§ä»·æ¯”', 'å¹³ä»·', 'äº²æ°‘'],
                'åˆ†é‡': ['åˆ†é‡', 'é‡è¶³', 'é‡å°‘', 'é‡å¤§', 'ç®¡é¥±'],
                'ç­‰å¾…æ—¶é—´': ['æ’é˜Ÿ', 'ç­‰ä½', 'ä¸Šèœå¿«', 'ä¸Šèœæ…¢', 'ç­‰å¾ˆä¹…']
            },
            'sentiment': {
                'positive': ['æ¨è', 'èµ', 'çˆ±äº†', 'æ»¡æ„', 'æƒŠå–œ', 'è¶…å‡ºé¢„æœŸ', 'å¿…åƒ'],
                'negative': ['å¤±æœ›', 'å·®', 'ä¸å€¼', 'å‘', 'ä¸ä¼šå†æ¥', 'è¸©é›·', 'åæ‚”']
            }
        }

    # ç©¿æ­åœºæ™¯
    elif any(word in keywords_lower for word in ['ç©¿æ­', 'æ­é…', 'è¡£æœ', 'è£™å­', 'è£¤å­', 'é‹å­']):
        return {
            'category': 'ç©¿æ­æ¨è',
            'features': {
                'é£æ ¼': ['é£æ ¼', 'ç©¿æ­', 'æ­é…', 'é€ å‹'],
                'å­£èŠ‚': ['æ˜¥ç§‹', 'å¤å­£', 'å†¬å­£', 'ä¿æš–', 'é€æ°”'],
                'èº«æ': ['æ˜¾ç˜¦', 'æ˜¾é«˜', 'å®½æ¾', 'ä¿®èº«', 'æ˜¾è…¿é•¿'],
                'ä»·æ ¼': ['å¹³ä»·', 'æ€§ä»·æ¯”', 'è´µ', 'ä¾¿å®œ', 'ç™½èœä»·'],
                'åœºåˆ': ['æ—¥å¸¸', 'çº¦ä¼š', 'å·¥ä½œ', 'åº¦å‡', 'è¿åŠ¨', 'é€šå‹¤']
            },
            'sentiment': {
                'positive': ['å¥½çœ‹', 'å–œæ¬¢', 'ç§è‰', 'å¿…ä¹°', 'å›è´­', 'æ˜¾ç™½'],
                'negative': ['ä¸‘', 'ä¸é€‚åˆ', 'å·®è¯„', 'é€€äº†', 'æ˜¾é»‘']
            }
        }

    # æ—…æ¸¸åœºæ™¯
    elif any(word in keywords_lower for word in ['æ—…æ¸¸', 'æ™¯ç‚¹', 'æ”»ç•¥', 'æ¸¸ç©', 'æ™¯ç‚¹', 'æ—…è¡Œ']):
        return {
            'category': 'æ—…æ¸¸æ”»ç•¥',
            'features': {
                'æ™¯ç‚¹': ['æ™¯ç‚¹', 'åèƒœ', 'å¤è¿¹', 'é£æ™¯', 'æ™¯è‰²', 'ç¾'],
                'äº¤é€š': ['äº¤é€š', 'æ–¹ä¾¿', 'åœ°é“', 'å…¬äº¤', 'æ‰“è½¦', 'å¥½èµ°'],
                'ä½å®¿': ['é…’åº—', 'æ°‘å®¿', 'ä½å®¿', 'å…¥ä½', 'æˆ¿é—´'],
                'ç¾é£Ÿ': ['ç¾é£Ÿ', 'å°åƒ', 'é¤å…', 'ç‰¹è‰²èœ', 'å¥½åƒ'],
                'è´¹ç”¨': ['é—¨ç¥¨', 'å…è´¹', 'ä¾¿å®œ', 'è´µ', 'æ€§ä»·æ¯”'],
                'å­£èŠ‚': ['æœ€ä½³å­£èŠ‚', 'ä»€ä¹ˆæ—¶å€™å»', 'å¤©æ°”', 'æ°”æ¸©']
            },
            'sentiment': {
                'positive': ['å€¼å¾—', 'æ¨è', 'ä¸è™šæ­¤è¡Œ', 'ç¾', 'æƒŠè‰³'],
                'negative': ['ä¸å€¼å¾—', 'å¤±æœ›', 'å•†ä¸šåŒ–', 'å‘', 'åæ‚”']
            }
        }

    # å­¦ä¹ /æ•™è‚²åœºæ™¯
    elif any(word in keywords_lower for word in ['å­¦ä¹ ', 'æ•™ç¨‹', 'è¯¾ç¨‹', 'python', 'ç¼–ç¨‹', 'å…¥é—¨', 'æŠ€å·§']):
        return {
            'category': 'å­¦ä¹ /æ•™ç¨‹',
            'features': {
                'éš¾åº¦': ['ç®€å•', 'å®¹æ˜“', 'å…¥é—¨', 'åŸºç¡€', 'è¿›é˜¶', 'éš¾'],
                'å®ç”¨æ€§': ['å®ç”¨', 'å¹²è´§', 'è¯¦ç»†', 'å…¨é¢', 'ç³»ç»Ÿ'],
                'æ—¶é•¿': ['çŸ­', 'é•¿', 'åˆ†é’Ÿ', 'å°æ—¶', 'å¤©'],
                'è´¹ç”¨': ['å…è´¹', 'æ”¶è´¹', 'ä¾¿å®œ', 'è´µ', 'æ€§ä»·æ¯”']
            },
            'sentiment': {
                'positive': ['æœ‰ç”¨', 'å­¦ä¼š', 'æ¨è', 'å¥½', 'æ¸…æ™°', 'è¯¦ç»†'],
                'negative': ['æ²¡ç”¨', 'å­¦ä¸ä¼š', 'å¤ªå¤æ‚', 'å·®', 'æµªè´¹æ—¶é—´']
            }
        }

    # é»˜è®¤è¿”å›Noneï¼ˆä½¿ç”¨é€šç”¨åˆ†æï¼‰
    return None

# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='MediaCrawler è‡ªåŠ¨åˆ†æå·¥å…·')
    parser.add_argument('--config', default='config/base_config.py',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/base_config.py)')
    parser.add_argument('--platform', type=str,
                       help='å¼ºåˆ¶æŒ‡å®šå¹³å° (xhs/dy/bili/wb/tieba/zhihu)')
    parser.add_argument('--contents', type=str,
                       help='å¼ºåˆ¶æŒ‡å®šå†…å®¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--comments', type=str,
                       help='å¼ºåˆ¶æŒ‡å®šè¯„è®ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶ï¼Œç›´æ¥åˆ†æ
    if args.contents:
        import sys
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))

        from claude.skills.mediacrawler_analyzer.analyze import analyze_mediacrawler_data

        results = analyze_mediacrawler_data(
            contents_file=args.contents,
            comments_file=args.comments
        )

    # å¦åˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
    else:
        results = analyze_from_config(args.config)
